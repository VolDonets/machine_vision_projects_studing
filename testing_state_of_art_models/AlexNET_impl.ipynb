{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78ef8995-92a3-4767-a282-886474a26659",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Import the dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48ff6e4a-61d5-4c18-aa9f-a35d0024e69a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers, optimizers\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ac9b9d-d7d9-4cbf-b70d-b43ab3a1b694",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bba1004-0f4b-426b-8210-259a0cb9b20c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "failed to allocate memory [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mResourceExhaustedError\u001B[0m                    Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-12-90458a4b090e>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mmd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     61\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 62\u001B[0;31m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_alexnet_model\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     63\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msummary\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-12-90458a4b090e>\u001B[0m in \u001B[0;36mget_alexnet_model\u001B[0;34m()\u001B[0m\n\u001B[1;32m     48\u001B[0m     \u001B[0;31m#FC_9 n=4096\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m     \u001B[0;31m#dropout\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDense\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0munits\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m4096\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mactivation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'relu'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mDropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0.5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    528\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    529\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 530\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    531\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    532\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprevious_value\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/keras/engine/sequential.py\u001B[0m in \u001B[0;36madd\u001B[0;34m(self, layer)\u001B[0m\n\u001B[1;32m    215\u001B[0m       \u001B[0;31m# If the model is being built continuously on top of an input layer:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    216\u001B[0m       \u001B[0;31m# refresh its output.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 217\u001B[0;31m       \u001B[0moutput_tensor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlayer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    218\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutput_tensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    219\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    975\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0m_in_functional_construction_mode\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_list\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    976\u001B[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001B[0;32m--> 977\u001B[0;31m                                                 input_list)\n\u001B[0m\u001B[1;32m    978\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    979\u001B[0m     \u001B[0;31m# Maintains info about the `Layer.call` stack.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m_functional_construction_call\u001B[0;34m(self, inputs, args, kwargs, input_list)\u001B[0m\n\u001B[1;32m   1113\u001B[0m       \u001B[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1114\u001B[0m       outputs = self._keras_tensor_symbolic_call(\n\u001B[0;32m-> 1115\u001B[0;31m           inputs, input_masks, args, kwargs)\n\u001B[0m\u001B[1;32m   1116\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1117\u001B[0m       \u001B[0;32mif\u001B[0m \u001B[0moutputs\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m_keras_tensor_symbolic_call\u001B[0;34m(self, inputs, input_masks, args, kwargs)\u001B[0m\n\u001B[1;32m    846\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmap_structure\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeras_tensor\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mKerasTensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutput_signature\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    847\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 848\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_infer_output_signature\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_masks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    849\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    850\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m_infer_output_signature\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput_masks\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m_infer_output_signature\u001B[0;34m(self, inputs, args, kwargs, input_masks)\u001B[0m\n\u001B[1;32m    884\u001B[0m           \u001B[0;31m# overridden).\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    885\u001B[0m           \u001B[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 886\u001B[0;31m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_build\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    887\u001B[0m           \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_cast_inputs\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    888\u001B[0m           \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcall_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36m_maybe_build\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m   2657\u001B[0m         \u001B[0;31m# operations.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2658\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0mtf_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmaybe_init_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2659\u001B[0;31m           \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbuild\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_shapes\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# pylint:disable=not-callable\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2660\u001B[0m       \u001B[0;31m# We must set also ensure that the layer is marked as built, and the build\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2661\u001B[0m       \u001B[0;31m# shape is stored since user defined build functions may not be calling\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/keras/layers/core.py\u001B[0m in \u001B[0;36mbuild\u001B[0;34m(self, input_shape)\u001B[0m\n\u001B[1;32m   1183\u001B[0m         \u001B[0mconstraint\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkernel_constraint\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1184\u001B[0m         \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1185\u001B[0;31m         trainable=True)\n\u001B[0m\u001B[1;32m   1186\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muse_bias\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1187\u001B[0m       self.bias = self.add_weight(\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer.py\u001B[0m in \u001B[0;36madd_weight\u001B[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001B[0m\n\u001B[1;32m    661\u001B[0m         \u001B[0msynchronization\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msynchronization\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    662\u001B[0m         \u001B[0maggregation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maggregation\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 663\u001B[0;31m         caching_device=caching_device)\n\u001B[0m\u001B[1;32m    664\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mregularizer\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    665\u001B[0m       \u001B[0;31m# TODO(fchollet): in the future, this should be handled at the\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/training/tracking/base.py\u001B[0m in \u001B[0;36m_add_variable_with_custom_getter\u001B[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001B[0m\n\u001B[1;32m    816\u001B[0m         \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    817\u001B[0m         \u001B[0minitializer\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minitializer\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 818\u001B[0;31m         **kwargs_for_getter)\n\u001B[0m\u001B[1;32m    819\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    820\u001B[0m     \u001B[0;31m# If we set an initializer and the variable processed it, tracking will not\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/keras/engine/base_layer_utils.py\u001B[0m in \u001B[0;36mmake_variable\u001B[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001B[0m\n\u001B[1;32m    127\u001B[0m       \u001B[0msynchronization\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msynchronization\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    128\u001B[0m       \u001B[0maggregation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maggregation\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 129\u001B[0;31m       shape=variable_shape if variable_shape else None)\n\u001B[0m\u001B[1;32m    130\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    264\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    265\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcls\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mVariableV1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 266\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_variable_v1_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    267\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mcls\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0mVariable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    268\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_variable_v2_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001B[0m in \u001B[0;36m_variable_v1_call\u001B[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001B[0m\n\u001B[1;32m    225\u001B[0m         \u001B[0msynchronization\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msynchronization\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    226\u001B[0m         \u001B[0maggregation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maggregation\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 227\u001B[0;31m         shape=shape)\n\u001B[0m\u001B[1;32m    228\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    229\u001B[0m   def _variable_v2_call(cls,\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m(**kwargs)\u001B[0m\n\u001B[1;32m    203\u001B[0m                         shape=None):\n\u001B[1;32m    204\u001B[0m     \u001B[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 205\u001B[0;31m     \u001B[0mprevious_getter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mlambda\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mdefault_variable_creator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    206\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mgetter\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_default_graph\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_variable_creator_stack\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    207\u001B[0m       \u001B[0mprevious_getter\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_make_getter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mgetter\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mprevious_getter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001B[0m in \u001B[0;36mdefault_variable_creator\u001B[0;34m(next_creator, **kwargs)\u001B[0m\n\u001B[1;32m   2624\u001B[0m         \u001B[0msynchronization\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msynchronization\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2625\u001B[0m         \u001B[0maggregation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maggregation\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2626\u001B[0;31m         shape=shape)\n\u001B[0m\u001B[1;32m   2627\u001B[0m   \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2628\u001B[0m     return variables.RefVariable(\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m    268\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_variable_v2_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    269\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 270\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mVariableMetaclass\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcls\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    271\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001B[0m\n\u001B[1;32m   1611\u001B[0m           \u001B[0maggregation\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maggregation\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1612\u001B[0m           \u001B[0mshape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1613\u001B[0;31m           distribute_strategy=distribute_strategy)\n\u001B[0m\u001B[1;32m   1614\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1615\u001B[0m   def _init_from_args(self,\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36m_init_from_args\u001B[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001B[0m\n\u001B[1;32m   1738\u001B[0m           \u001B[0;32mwith\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mname_scope\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Initializer\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdevice_context_manager\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1739\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0minit_from_fn\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1740\u001B[0;31m               \u001B[0minitial_value\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0minitial_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1741\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0misinstance\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minitial_value\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrackable\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mCheckpointInitialValue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1742\u001B[0m               \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_maybe_initialize_trackable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/keras/initializers/initializers_v2.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, shape, dtype, **kwargs)\u001B[0m\n\u001B[1;32m    515\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    516\u001B[0m       \u001B[0mlimit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqrt\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m3.0\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mscale\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 517\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_random_generator\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom_uniform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m-\u001B[0m\u001B[0mlimit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlimit\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    518\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    519\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mget_config\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/keras/initializers/initializers_v2.py\u001B[0m in \u001B[0;36mrandom_uniform\u001B[0;34m(self, shape, minval, maxval, dtype)\u001B[0m\n\u001B[1;32m    971\u001B[0m       \u001B[0mop\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrandom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0muniform\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    972\u001B[0m     return op(\n\u001B[0;32m--> 973\u001B[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001B[0m\u001B[1;32m    974\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    975\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mtruncated_normal\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmean\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstddev\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    205\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 206\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    207\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    208\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/random_ops.py\u001B[0m in \u001B[0;36mrandom_uniform\u001B[0;34m(shape, minval, maxval, dtype, seed, name)\u001B[0m\n\u001B[1;32m    313\u001B[0m           \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmath_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmultiply\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmaxval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    314\u001B[0m       \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 315\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmath_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mresult\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mmaxval\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mminval\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mminval\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    316\u001B[0m     \u001B[0;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    317\u001B[0m     \u001B[0;31m# cross FuncGraph boundaries since that information is only available in\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    204\u001B[0m     \u001B[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    205\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 206\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mtarget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    207\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mTypeError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    208\u001B[0m       \u001B[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\u001B[0m in \u001B[0;36madd\u001B[0;34m(x, y, name)\u001B[0m\n\u001B[1;32m   3941\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3942\u001B[0m     \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3943\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mgen_math_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd_v2\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   3944\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3945\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\u001B[0m in \u001B[0;36madd_v2\u001B[0;34m(x, y, name)\u001B[0m\n\u001B[1;32m    453\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0m_result\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    454\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 455\u001B[0;31m       \u001B[0m_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from_not_ok_status\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    456\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0m_core\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_FallbackException\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    457\u001B[0m       \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001B[0m in \u001B[0;36mraise_from_not_ok_status\u001B[0;34m(e, name)\u001B[0m\n\u001B[1;32m   6939\u001B[0m   \u001B[0mmessage\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmessage\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m\" name: \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mname\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6940\u001B[0m   \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6941\u001B[0;31m   \u001B[0msix\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mraise_from\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_status_to_exception\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcode\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmessage\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6942\u001B[0m   \u001B[0;31m# pylint: enable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6943\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.local/lib/python3.6/site-packages/six.py\u001B[0m in \u001B[0;36mraise_from\u001B[0;34m(value, from_value)\u001B[0m\n",
      "\u001B[0;31mResourceExhaustedError\u001B[0m: failed to allocate memory [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "def get_alexnet_model():\n",
    "    md = Sequential()\n",
    "    \n",
    "    #CONV_1 (input 227x227x3), depth=96, kernel=11x11, strides=4 (output 55x55x96)\n",
    "    #       activation relu\n",
    "    #POOL_2 pool_size=3, stride=2 (output 27x27x96)\n",
    "    #batchnorm\n",
    "    md.add(Conv2D(filters=96, kernel_size=11, strides=4, padding='valid',\n",
    "                  activation='relu',\n",
    "                  input_shape=(227, 227, 3)))\n",
    "    md.add(MaxPooling2D(pool_size=3, strides=2))\n",
    "    md.add(BatchNormalization())\n",
    "    \n",
    "    #CONV_3 depth=256, kernel=5, padding=2, strides=1 (output 27x27x256)\n",
    "    #POOL_4 pool_size=3, stride=2 (output 13x13x256)\n",
    "    #batchnorm\n",
    "    md.add(Conv2D(filters=256, kernel_size=5, strides=1, padding='same',\n",
    "                  kernel_regularizer=regularizers.l2(0.0005),\n",
    "                  activation='relu'))\n",
    "    md.add(MaxPooling2D(pool_size=3, strides=2))\n",
    "    md.add(BatchNormalization())\n",
    "    \n",
    "    #CONV_5 depth=384, kernel, padding=1, stride=1 (output 13x13x384)\n",
    "    #batchnorm\n",
    "    md.add(Conv2D(filters=384, kernel_size=3, strides=1, padding='same',\n",
    "                  kernel_regularizer=regularizers.l2(0.0005),\n",
    "                  activation='relu'))\n",
    "    md.add(BatchNormalization())\n",
    "    \n",
    "    #CONV_6 k=384, f=3x3, padding=1, stride=1 (output 13x13x384)\n",
    "    md.add(Conv2D(filters=384, kernel_size=3, strides=1, padding='same',\n",
    "                  kernel_regularizer=regularizers.l2(0.0005),\n",
    "                  activation='relu'))\n",
    "    md.add(BatchNormalization())\n",
    "    \n",
    "    #CONV_7 k=256, f=3x3, padding=1, stride=1 (output 13x13x256)\n",
    "    md.add(Conv2D(filters=256, kernel_size=3, strides=1, padding='same',\n",
    "                  kernel_regularizer=regularizers.l2(0.0005),\n",
    "                  activation='relu'))\n",
    "    md.add(BatchNormalization())\n",
    "    \n",
    "    #POOL_8 f=3x3, stride=2 (output 6x6x256)\n",
    "    md.add(MaxPooling2D(pool_size=3, strides=2))\n",
    "    \n",
    "    #FLATTEN\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    #FC_9 n=4096\n",
    "    #dropout\n",
    "    model.add(Dense(units=4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    #FC_10 n=4096\n",
    "    model.add(Dense(units=4096, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    #SOFT_MAX n=1000\n",
    "    model.add(Dense(units=1000, activation='softmax'))    \n",
    "    \n",
    "    return md\n",
    "\n",
    "model = get_alexnet_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf31315-be58-4e95-b151-90c60cae5c71",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create the model by book:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d79aa4c-5fab-42c7-8918-1a3578642486",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 27, 27, 96)        384       \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 27, 27, 256)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 13, 13, 384)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 13, 13, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 13, 13, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              37752832  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 62,383,848\n",
      "Trainable params: 62,381,096\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def get_alexnet_model2():\n",
    "    md = Sequential()\n",
    "    \n",
    "    # 1st layer (CONV + POOL + batchnorm)\n",
    "    md.add(Conv2D(filters=96, kernel_size=(11, 11), strides=(4, 4),\n",
    "                  padding='valid', input_shape=(227, 227, 3)))\n",
    "    md.add(Activation('relu'))\n",
    "    md.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
    "    md.add(BatchNormalization())\n",
    "    \n",
    "    # 2nd layer (CONV + POOL + batchnorm)\n",
    "    md.add(Conv2D(filters=256, kernel_size=(5, 5), strides=(1, 1),\n",
    "                  padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    md.add(Activation('relu'))\n",
    "    md.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n",
    "    md.add(BatchNormalization())\n",
    "    \n",
    "    # 3rd layer (CONV + batchnorm)\n",
    "    md.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1),\n",
    "                  padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    md.add(Activation('relu'))\n",
    "    md.add(BatchNormalization())\n",
    "    \n",
    "    # 4th layer (CONV + batchnorm)\n",
    "    md.add(Conv2D(filters=384, kernel_size=(3, 3), strides=(1, 1),\n",
    "                  padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    md.add(Activation('relu'))\n",
    "    md.add(BatchNormalization())\n",
    "    \n",
    "    # 5th layer (CONV  + batchnorm + POOLING)\n",
    "    md.add(Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1),\n",
    "                  padding='same', kernel_regularizer=regularizers.l2(0.0005)))\n",
    "    md.add(Activation('relu'))\n",
    "    md.add(BatchNormalization())\n",
    "    md.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='valid'))\n",
    "    \n",
    "    # Flatten\n",
    "    md.add(Flatten())\n",
    "    \n",
    "    # 6th layer (Dense + dropout)\n",
    "    md.add(Dense(units=4096, activation='relu'))\n",
    "    md.add(Dropout(0.5))\n",
    "    \n",
    "    # 7th layer (Dense + dropout)\n",
    "    md.add(Dense(units=4096, activation='relu'))\n",
    "    md.add(Dropout(0.5))\n",
    "    \n",
    "    # 8th layer (softmax output)\n",
    "    md.add(Dense(units=1000, activation='softmax'))\n",
    "    \n",
    "    return md\n",
    "\n",
    "model = get_alexnet_model2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf642af0-b353-4dd0-8398-784b3229d475",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## setting up the learning hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e86d9f9b-c8e1-4cc5-a0e0-455a2e65bc16",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras.callbacks as callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6761a3f9-4dbf-4b19-b700-597b75c4dfc4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reduce_lr = callbacks.ReduceLROnPlateau(monitor='val_loss', factor=np.sqrt(0.1))\n",
    "optimizer = tensorflow.keras.optimizers.SGD(lr = 0.01, momentum = 0.9)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ab4a8-d586-4464-b6e2-9aef9f053315",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=90,\n",
    "          validation_data=(X_test, y_test), verbose=2, \n",
    "          callbacks=[reduce_lr])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}